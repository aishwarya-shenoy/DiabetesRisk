
# Overview
Diabetes, a pervasive and life-threatening chronic disease, has witnessed a surge in global prevalence, emphasizing the critical need for early diagnosis and intervention to avert severe complications [1][2]. This necessitates robust predictive models, and machine learning (ML) has emerged as a promising tool for diabetes prediction. However, challenges such as limited labeled data, missing values, and dataset imbalance pose obstacles to the development of accurate models [2]. Addressing these challenges is crucial to enhance predictive performance and enable timely intervention.
The ramifications of diabetes are far-reaching, affecting vital organs and contributing to conditions such as heart disease, kidney issues, nerve damage, and blindness if left untreated [3]. Timely prediction of diabetes not only saves lives but also empowers healthcare professionals to proactively manage the condition. Despite the wealth of data generated by basic information systems in hospitals, converting this data into actionable insights for clinical decision-making remains a challenge. Automated techniques, such as ensemble learning, offer a promising avenue to integrate diverse methods into a cohesive predictive system, overcoming bias and variability [3].
Diabetes Mellitus, a significant health concern, is influenced by factors such as age, obesity, genetics, and lifestyle [4]. Big Data Analytics, a pivotal player in healthcare, allows for the study of large datasets to uncover hidden patterns and knowledge. Existing methods, however, exhibit suboptimal classification accuracy. Some studies propose a diabetes prediction model incorporating external factors alongside traditional variables, achieving enhanced classification accuracy [4].
The economic and healthcare burden of diabetes necessitates highly accurate predictive methods. Artificial Intelligence (AI) systems, particularly Artificial Neural Networks (ANN), offer a reliable approach. In this context, a study utilizing ANN achieved an accuracy of 87.3% in predicting diabetes status, highlighting the potential of AI in addressing this critical issue [5].
The identification and diagnosis of diabetes often involve complex and time-consuming processes. Machine learning approaches, including Decision Trees, Support Vector Machines (SVM), and Naive Bayes, present a solution to this challenge. A study employing these algorithms on the Pima Indians Diabetes Database demonstrated the potential for early-stage diabetes detection, with Naive Bayes outperforming other algorithms [6].
The increasing global prevalence of diabetes underscores the urgency of accurate predictive models. Machine learning techniques offer a promising avenue, but challenges persist.
Problem Statement
In addressing the formidable challenge of diabetes, a disease causing a significant number of deaths annually and often diagnosed at later stages, our project aims to identify individuals at risk of developing diabetes at an early stage. Early detection empowers individuals to adopt preventive measures and make informed lifestyle changes, contributing to the reduction of diabetes-related complications. Our primary goal is to leverage logistic regression, a powerful classification model in machine learning, for the prediction and interpretation of diabetes risk based on a comprehensive set of health indicators and lifestyle choices. 
To achieve this goal, our study incorporates a diverse range of independent variables encompassing health indicators, eating habits, demographic information, and lifestyle choices. These variables, both qualitative and quantitative, include blood pressure level, cholesterol level, BMI, smoking habit, heart diseases/stroke, alcohol consumption, exercise habit, types of food intake, healthcare coverage, sex, age, education level, and income level. The dependent variable is a qualitative indicator denoting whether an individual has diabetes or not. 
Several research papers underscore the efficacy of logistic regression in diabetes prediction. For instance, a study combining PCA, k-means clustering, and logistic regression demonstrates enhanced accuracy compared to traditional methods. By refining the k-means clustering algorithm using PCA, the logistic regression model achieves a 1.98% higher accuracy, making it a valuable tool for predicting diabetes based on patient electronic health records [7]. 
In another approach, logistic regression is explored as a classification model extensively employed in clinical analysis. Recognizing the potential of early diabetes detection, the study designs a prediction model utilizing diagnostic measurements. Various techniques are employed to boost the model's performance and accuracy, emphasizing the importance of logistic regression in predicting diabetes and informing clinical decisions [8]. 
In summary, our project employs logistic regression as a key tool for diabetes prediction, leveraging its probabilistic estimations to understand the intricate relationship between independent variables and the likelihood of diabetes. Through this approach, we seek to not only predict diabetes accurately but also contribute to the interpretability of the model, enabling clinicians and individuals to comprehend the impact of various health factors on diabetes risk.

# Data Description 
The data for this project will be obtained from Kaggle. This dataset was obtained from a telephone survey done by the CDC in 2015. This data set is not time dependent as all data points were collected in the same year, 2015. It consists of 70,692 records, each representing an individual. 22 variables are in this data set, and we will perform some variable selection processes to decide what predictors to use.
S.No 	 Variable Name         	 Variable Type    	 Role                                                  
1	 Diabetes_binary       	 Qualitative          	 A binary indicator for the presence or absence of diabetes (Yes = 1, No = 0).
2	 HighBP                	 Qualitative          	 Identifies individuals with high blood pressure (0 = No, 1 = Yes).
3	 HighChol              	 Qualitative          	 Identifies individuals with high cholesterol levels (0 = No, 1 = Yes).
4	 CholCheck             	 Qualitative          	 Indicates whether individuals have had their cholesterol levels checked (0 = No, 1 = Yes in the last 5 years).
5	 BMI                   	 Quantitative         	 Represents Body Mass Index (BMI).
6	 Smoker                	 Qualitative          	 Captures whether individuals have smoked at least 100 cigarettes in their lifetime (0 = No, 1 = Yes).
7	 Stroke                	 Qualitative          	 Has the individual had a stroke (0 = No, 1 = Yes).
8	 HeartDiseaseorAttack  	 Qualitative          	 Coronary Heart Disease (CHD) or Myocardial Infarction (MI) (0 = No, 1 = Yes).
9	 PhysActivity          	 Qualitative          	 Physical activity in the last thirty days excluding job (0 = No, 1 = Yes).
10	 Fruits                	 Qualitative          	 Consumes fruit 1 or more times daily (0 = No, 1 = Yes).
11	 Veggies               	 Qualitative          	 Consumes vegetables 1 or more times daily (0 = No, 1 = Yes).
12	 HvyAlcoholConsump     	 Qualitative          	 Identifies heavy drinkers based on alcohol consumption (0 = No, 1 = Yes).
13	 AnyHealthcare         	 Qualitative          	 Captures whether individuals have any form of healthcare coverage (0 = No, 1 = Yes).
14	 NoDocbcCost           	 Qualitative          	 Indicates instances when individuals couldn't see a doctor in the past 12 months due to cost (0 = No, 1 = Yes).
15	 GenHlth               	 Qualitative          	 Measures general health on a scale of 1-5 (1 = Excellent, 2 = Very Good, 3 = Good, 4 = Fair, 5 = Poor).
16	 MentHlth              	 Quantitative         	 Quantifies the number of days during the past 30 days when individuals experienced poor mental health (scale 1-30 days).
17	 PhysHlth              	 Quantitative         	 Quantifies the number of days during the past 30 days when individuals experienced physical illness or injury (scale 1-30 days).
18	 DiffWalk              	 Qualitative          	 Indicates if individuals have serious difficulty walking or climbing stairs (0 = No, 1 = Yes).
19	 Sex                   	 Qualitative          	 Captures the sex of individuals (0 = Female, 1 = Male).
20	 Age                   	 Qualitative          	 Represents 13 age categories (1=18-24, 9=60-64,13=80+).
21	 Education             	 Qualitative          	 Reflects education levels (Scale 1-6. 1 = Never attended school or only kindergarten, 2 = elementary etc.).
22	 Income                	 Qualitative          	 Indicates income levels (Scale 1-8. 1= <$10,000, 5= < $35,000, 8 = $85,000+).

For the purposes of this project, we will only be examining individuals who are male and are in the age group of 18-64. From this subset of the data, we randomly chose 1,500 data points for our regression model.
The dependent variable is the Diabetes_binary column, which is a qualitative variable. The rest of the variables are independent variables, which are the predictors of diabetes. Diabetes_binary = 1 includes individuals with either prediabetes or diabetes. Prediabetes is a severe health condition where the blood sugar levels are higher than usual, but not high enough to be considered as diabetes.

# Exploratory Data Analysis 
To obtain insights into each predicting factor and how it is related to the independent variable, we conducted an exploratory data analysis, aiming to understand the data set more clearly before creating the model. We have a total of 17 qualitative variables and 3 quantitative variables. Since the independent variable is a qualitative measure, we cannot use a scatter plot or a correlation plot, such as a heatmap, to illustrate the correlation between the variables as it only applies to quantitative measures. Instead, we utilized a combination of bar plot, box plot, and histogram to perform the exploratory data analysis. 
The quantitative predictors are BMI (Body Mass Index), MentHlth (days of poor mental health), and PhysHlth (days of poor physical health). For BMI, we created a histogram and a boxplot for people who have diabetes (Diabetes_binary = 1) and those who do not have diabetes (Diabetes_binary = 0). Both plots are shown above, where the figure on the left-hand side is a histogram illustrates the distribution of the BMI by their diabetes status, and the figure on the right-hand side is the boxplot shows the distribution of the BMI by diabetes status shown in different colors. Red indicates an absence of diabetes and blue represents a presence of diabetes. As seen in the figures, the distribution of BMI is rightly skewed with several outliers having a BMI greater than 40, regardless of diabetes status. In general, a greater than 30 BMI value indicates obesity. Thus, we can see that the median BMI for people with diabetes is slightly higher than those who do not have diabetes. People who have diabetes tend to have a median BMI value close to 30, which indicates a higher chance of obesity compared to people who do not have diabetes. 
MentHlth and PhysHlth also share similar distribution as shown in the figures [Appendix B Figure 14, 15]. Most people reported 0 days of poor mental or physical health, and out of these people, most of them do not have diabetes presence. However, it is important to note that there is still a significant amount of people who do not have poor mental or physical health conditions but are still diagnosed with diabetes. Overall, there is no significant impact of poor physical or mental health on diabetes risk. However, we do see several extreme cases where the days of poor mental or physical health are 30. In this case, the number of people with diabetes is greater than those who do not. 
For qualitative variables, we utilized bar plots to examine the distribution of the variables in terms of the Diabetes_binary variable. Since there are 17 qualitative variables, we will only focus on the first 8 variables, and the rest of the analysis will be provided in appendix B. Education, GenHlth, Smoker, Income, Stroke, Age, HighBP, and HighChol are the focus of this analysis. Based on the bar plot, Education seems to have no significant effect on diabetes risk as the number of diabetes and non-diabetes count looks similar for both cases [Appendix B Figure 1]. For GenHlth (general health), the risk of diabetes increases when people indicate that they are in good health condition [Appendix B Figure 2]. People who smoke seem to have an equal risk of diabetes to those who do not smoke [Appendix B Figure 4]. It is interesting to note that diabetes risk is higher among the higher income groups compared to the lower income groups according to the data [Appendix B Figure 3]. 
In this CDC 2015 health survey, there are not many people who reported having a stroke, but among those who did, their diabetes risk seems to be a little higher than those who do not [Appendix B Figure 5]. Most of the people surveyed do not have a stroke condition and their diabetes vs. non-diabetes count seems to be similar, indicating that stroke might not be a significant factor for diabetes. In terms of age, the risk of diabetes increases significantly with age. High blood pressure and cholesterol levels also lead to high diabetes risk [Appendix B Figure 7, 8]. 
By conducting the above exploratory data analysis, our team was able to obtain further insights into the data set by examining the relationships between various predicting variables and diabetes risk. This helped us prepare for the model fitting process.

# Model Fitting
After completing our exploratory analysis, we settled on using a logistic regression model for our prediction due to the following reasons: 
1.	Better prediction in scenarios where the dependent variable is binary.
2.	Better prediction in scenarios where the relationship between the independent variables and dependent variables is not linear.
3.	Better interpretability of results in terms of odds ratios. 
4.	More robust to outliers and imbalanced data in the independent variables.

Model 1: Complete Model
Before fitting the model, we initially divided our dataset into training and testing sets using an 80:20 ratio, allocating 80% for training and the remaining 20% for testing.
The first model for our analysis included all 20 of the predicting variables. The Logistic Regression model summary is given below. 
Significance of Coefficients:
By comparing the p-value for each of the coefficients (given in far-right column) to our significance level α = 0.05, we can identify the following as significant coefficients (since their P-Value < α):
•	HighBP
•	HighChol
•	BMI
•	HvyAlcoholConsump

For the following coefficients, only certain categories/values have a p-value lower than the significance level:
•	GenHlth
•	Age
•	MentHlth
•	PhysHlth

Considering the above, we can make a few preliminary observations: 
•	High Blood Pressure, High Cholesterol levels and high BMI all increased the risk of diabetes. Surprisingly, a higher level of alcohol consumption lowers the risk of diabetes.
•	Individuals with poorer general health are at a higher risk of getting diabetes. 
•	Up to age 45, the risk of diabetes is not linked with the age of the individual. Post that point, the risk of diabetes increases with age.
•	Except for MentHlth = 14, none of the other values of MentHlth are significant, which indicates that Mental Health related issues are not closely related to increased diabetes risk. 
•	Similarly, except for two values of PhysHlth, none of the other values of PhysHlth are significant, which indicates that Physical Health related issues are not closely related to increased diabetes risk.
Note: For the last two points above, it is important to note that these data points rely on the user reporting their physical and mental health over the month, and not actual hospital/patient data, thus we cannot sufficiently conclude that mental and physical wellbeing are not significant to diabetes risk at all.
•	Factors such as Education Level, Income level, consumption of fruits and vegetables, doctor visits, difficulty in walking, etc. do not significantly increase or decrease the risk of diabetes in the adult male population.
Test for Overall Regression: 
Here we tested to see if the 20 predictors can be used to explain the variability of diabetes, by performing a hypothesis test using an alpha value of 0.05. 

Null Hypothesis: There are no predictors that can explain the variability in diabetes, i.e., all regression coefficients are zero.
Alternate Hypothesis: There are predictors that can explain the variability in diabetes, i.e., at least one regression coefficient is a non-zero value.

To test the hypothesis, we calculated the test statistic and the respective P-Value. We got our test statistics by calculating the difference between null deviance and deviance of the fitted model and obtaining its p-value using the Chi Square distribution. [Appendix C Figure 1] We obtained 434.2018 as the difference in deviance and 0 for its p-value. As the p-value is lesser than significance level α = 0.05, we reject the null hypothesis. Based on the results obtained, we can conclude that there are predictors that can explain the variability in diabetes, i.e., at least one regression coefficient is a non-zero value.

Test for Goodness of Fit: 
Here we test to see if the model fits well with our dataset based on an alpha value of 0.05. 
Null Hypothesis: The model is a good fit for our dataset.
Alternate Hypothesis: The model is not a good fit for our dataset.
To test our hypothesis, we calculated the test statistics and the respective P-Value. We got our test statistics by calculating the difference between null deviance and deviance of the fitted model and obtaining its p-value using the Chi Square distribution. We also calculated the Pearson Residual, and its corresponding P-value [Appendix C Figure 2]. In both cases, the p-value is greater than significance level α of 0.05, thus we fail to reject the null hypothesis. Based on the hypothesis test result, we can conclude that the model is a good fit. 

While the deviance and Pearson residuals tests indicate that the model is a good fit, our group decided to conduct variable selection to improve model performance by increasing prediction accuracy and removing any redundant or irrelevant predictors.

Why no residual analysis?

In an attempt to create a proportion logistic regression model to illustrate the relationships between the aggregated data with the proportion of people who have diabetes, our group found that, due to the complexity of the data, aggregating the data generated too many different sets of unique values. This made the proportion logistic regression not applicable to our data set. Thus, we decided to build a prediction model using the regular logistic regression with a binary variable as the response variable. This means that the residual analysis is not applicable as the Pearson and deviance residuals will not have a normal distribution. (However, we still assumed that the residuals are independent based on the nature of how the survey data was collected.) This also indicates that the Cook’s distance test for outliers will not be applicable in our study. 
Both histogram and normal Q-Q plot below show that normality is not met because of the binary response variable in logistic regression. The histogram does not exhibit a bell curve shape and the Q-Q plot deviates from the reference line.  
  
Model 2: Final Model
Variable Selection
To improve our model performance, we undertook variable selection. We started with the full model and applied Forward Step Regression, Backward Step Regression, and Lasso Regression. These three approaches are common variable selection methods for regression analysis. The goal is to find one method that yields the lowest AIC value. The resulting model from our Forward Step Regression had eight predicting factors and an AIC of 1252.91 [Appendix C Figure 2]. Similarly, the Backward Step Regression had eight predicting factors and an AIC of 1252.91 [Appendix C Figure 4]. Finally, the Lasso model had 20 predicting variables and an AIC of 1281.1  [Appendix C Figure 6].
Residual Analysis
Similarly, to the full model, we do not have any residual analysis here. Proportion logistic regression is still not viable due to the complexity of the data.
Next, we looked at the variance inflation factors to check for multicollinearity. As you can see from the results [Appendix C Figure 10], all the VIFs are only slightly above one and well within the threshold to say that there is no multicollinearity.
Test for Overall Regression
To test if the selected variables can be used to explain the variability of diabetes, we performed a test for overall regression and used an alpha value of 0.05.
Null Hypothesis: All regression coefficients are zero.
Alternate Hypothesis: At least one regression coefficient is a non-zero value.
The results in Appendix C Figure 8 show a P-value of 0 for our GSTAT test, thus we are able to reject the Null Hypothesis and find that at least one of the variables is significant.
Test for Goodness-of-Fit 
Before using this model to test prediction accuracy on our test data, we checked the Goodness-of-Fit [Appendix C Figure 9].
Our hypotheses for both the Pearson test and Deviance test are: 
Null Hypothesis: The model is a good fit for the data.
Alternative Hypothesis: The model is not a good fit for the data.
Because the resulting P-values above are greater than the alpha we are using for this project of 0.05 , we can fail to reject the Null Hypothesis and conclude that our model is a good fit for the data. Thus, no further modification is needed. 
Prediction Accuracy and Model Validation
Once we had our model, we used it to predict on the testing data and attained 74.1% prediction accuracy using a threshold of 50%. In the medical field, it is better to temporarily think you have the condition when you do not than the reverse. This means that we would rather have a higher number of false positives (Type II errors) than the false negatives (Type I errors). In order to reduce the false negatives, we changed to a threshold of 40%. This barely affects the overall prediction rate which becomes 74.7%, but as you can see it lowered the number of missed diabetes cases [Figure: 0.4 Final Model Confusion Matrix]. For comparison, I have also included the full model at a threshold of 40%, where it attains an accuracy of 73.1% [Figure: 0.4 Full Model Confusion Matrix].
  
Overall, this secondary model performs better and is much more interpretable than the original full model.

# Conclusions 
By conducting the exploratory data analysis, the first model fitting, variable selection, and the final model fitting, our team was able to create a logistic regression to predict diabetes risk. We identified that there are 8 significant factors that impact diabetes risks among the male population in the age of 18 to 64: general health, age, high blood pressure, high cholesterol levels, BMI, heavy alcohol consumption, cholesterol check, and stroke. The odds of diabetes for general health level of 2 to 5 increases by a significant amount, with the highest being e^2.11673 = 8.3 – 1 = 730% compared to a general health level of 1, while holding others constant [Appendix C Figure 7]. This indicates that males have a higher diabetes risk if they identify their general health status as anything other than “excellent”. A male’s diabetes risk also increases when having high blood pressure, high cholesterol level, stroke, or cholesterol check compared to those who do not. Furthermore, we found that the odds of diabetes for non-heavy alcohol consumption decrease by 1 - e^-1.14 = 68% compared to those with heavy alcohol consumption, holding others constant. This is an interesting finding because our group assumed the opposite result. Lastly, as the age increases, the risk of diabetes also increases based on the model result. 
This logistic regression model can be widely adapted by multiple domains in the healthcare industry. For example, a health insurance company may want to know how to personalize the best, most suitable healthcare plan for its customers. By using metrics such as age, income, BMI, cholesterol levels, blood pressure, alcohol consumption, etc., the company can categorize customers into low and high diabetes risk groups. They can then provide suitable healthcare options, medical assistance, and other necessary products accordingly and efficiently. Even if a customer is not diagnosed with diabetes, classifying them into high or low diabetes risk groups can help both the customers and the company to come up with preventive plans or precautions such as the change to a healthier lifestyle or any helpful medications/medical treatments. 
Based on the confusion matrix shown previously, the prediction accuracy of the final logistic model is 74%. The classification threshold is set at 0.4 because in predicting health-related measures, we want to be conservative. It is better to wrongfully predict a person with high diabetes risk when they are healthy than misclassifying a person to be in low diabetes risk when in fact, they have high diabetes risk. Thus, we want to minimize the number of Type I errors. Since the prediction accuracy for the final model (74%) is higher than the initial model (73%), we conclude that our logistic prediction model for diabetes risk is a good model. 
To further improve the model, our group plans on incorporating more data from the original raw dataset to include the female population in our analysis. We would compare the model results and obtain insights on the diabetes risks for females as well as further explore any significant findings. 
